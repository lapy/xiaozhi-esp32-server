<!DOCTYPE html>
<html lang="en-US">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Xiaozhi Server Test Page</title>
    <link rel="stylesheet" href="test_page.css">
    <style>
        #fileProtocolWarning {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background-color: rgba(0, 0, 0, 0.8);
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            z-index: 9999;
            color: white;
            padding: 20px;
            box-sizing: border-box;
        }

        #fileProtocolWarning h2 {
            color: #ff4d4d;
            margin-bottom: 20px;
        }

        #fileProtocolWarning pre {
            background-color: green;
            font-size: 18px;
            padding: 15px;
            border-radius: 5px;
            font-family: monospace;
            overflow-x: auto;
            margin: 15px 0;
        }

        #fileProtocolWarning button {
            background-color: #4CAF50;
            color: white;
            border: none;
            padding: 10px 20px;
            text-align: center;
            text-decoration: none;
            display: inline-block;
            font-size: 16px;
            margin: 10px 2px;
            cursor: pointer;
            border-radius: 4px;
        }

        #fileProtocolWarning button:hover {
            background-color: #45a049;
        }
    </style>
    <script>
        // Check if opened using file:// protocol
        if (window.location.protocol === 'file:') {
            document.addEventListener('DOMContentLoaded', function () {
                // Create warning box
                const warningDiv = document.createElement('div');
                warningDiv.id = 'fileProtocolWarning';
                warningDiv.innerHTML = `
                    <h2>⚠️ Warning: Please use HTTP server to open this page</h2>
                    <p>You are currently opening the page using local file method (file:// protocol), which may cause page functionality issues.</p>
                    <p>You can use nginx mapping to start the test page, or follow these steps to use python to start the test http service:</p>
                    <ol>
                        <li>Open command line terminal</li>
                        <li>Navigate to xiaozhi-server/test directory in command line</li>
                        <li>Execute the following command to start HTTP server:</li>
                    </ol>
                    <pre>python -m http.server 8006</pre>
                    <p>Then access in browser: <strong>http://localhost:8006/test_page.html</strong></p>
                `;
                document.body.appendChild(warningDiv);
            });
        }
    </script>
</head>

<body>
    <div class="container">
        <h1>Xiaozhi Server Test Page</h1>

        <div id="scriptStatus" style="position: fixed; top: 50%; left: 50%; transform: translate(-50%, -50%);">
            Loading Opus library...
        </div>

        <!-- Add configuration panel -->
        <div class="section">
            <h2>
                Device Configuration
                <span class="device-info">
                    <span>MAC: <strong id="displayMac"></strong></span>
                    <span>Client: <strong id="displayClient">web_test_client</strong></span>
                </span>
                <button class="toggle-button" id="toggleConfig">Edit</button>
            </h2>
            <div class="config-panel" id="configPanel">
                <div class="control-panel">
                    <div class="config-item">
                        <label for="deviceMac">Device MAC:</label>
                        <input type="text" id="deviceMac" placeholder="Device MAC address">
                    </div>
                    <div class="config-item">
                        <label for="deviceName">Device Name:</label>
                        <input type="text" id="deviceName" value="Web Test Device" placeholder="Device name">
                    </div>
                    <div class="config-item">
                        <label for="clientId">Client ID:</label>
                        <input type="text" id="clientId" value="web_test_client" placeholder="Client ID">
                    </div>
                    <div class="config-item">
                        <label for="token">Authentication Token:</label>
                        <input type="text" id="token" value="your-token1" placeholder="Authentication token">
                    </div>
                </div>
            </div>
        </div>

        <div class="section">
            <h2>
                Connection Information
                <span class="connection-status">
                    <span>OTA: <span id="otaStatus" class="status">ota not connected</span></span>
                    <span>WS: <span id="connectionStatus" class="status">ws not connected</span></span>
                </span>
            </h2>
            <div class="connection-controls">
                <input type="text" id="otaUrl" value="http://127.0.0.1:8002/xiaozhi/ota/"
                    placeholder="OTA server address, e.g.: http://127.0.0.1:8002/xiaozhi/ota/" />
                <input type="text" id="serverUrl" value="ws://127.0.0.1:8000/xiaozhi/v1/"
                    placeholder="WebSocket server address, e.g.: ws://127.0.0.1:8000/xiaozhi/v1/" />
                <button id="connectButton">Connect</button>
                <button id="authTestButton">Test Auth</button>
            </div>
        </div>

        <div class="section">
            <div class="tabs">
                <button class="tab active" data-tab="text">Text Message</button>
                <button class="tab" data-tab="voice">Voice Message</button>
            </div>

            <div class="tab-content active" id="textTab">
                <div class="message-input">
                    <input type="text" id="messageInput" placeholder="Enter message..." disabled>
                    <button id="sendTextButton" disabled>Send</button>
                </div>
            </div>

            <div class="tab-content" id="voiceTab">
                <div class="audio-controls">
                    <button id="recordButton" class="record-button" disabled>Start Recording</button>
                </div>
                <canvas id="audioVisualizer" class="audio-visualizer"></canvas>
            </div>
        </div>

        <div class="section">
            <h2>Conversation History</h2>
            <div class="flex-container">
                <div id="conversation" class="conversation"></div>
                <div id="logContainer">
                    <div class="log-entry log-info">Ready, please connect to the server to start testing...</div>
                </div>
            </div>
        </div>
    </div>

    <!-- Opus decoding library -->
    <script src="libopus.js"></script>

    <script type="module">
        import { log } from './js/utils/logger.js';
        import { webSocketConnect } from './js/xiaoZhiConnect.js';
        import { checkOpusLoaded, initOpusEncoder } from './js/opus.js';
        import { addMessage } from './js/document.js'
        import BlockingQueue from './js/utils/BlockingQueue.js'
        import { createStreamingContext } from './js/StreamingContext.js'
        // List of scripts to load - remove Opus dependency
        const scriptFiles = [];

        // Script loading status
        const scriptStatus = {
            loading: 0,
            loaded: 0,
            failed: 0,
            total: scriptFiles.length
        };

        // Global variables
        let websocket = null;
        let mediaRecorder = null;
        let audioContext = null;
        let analyser = null;
        let audioChunks = [];
        let isRecording = false;
        let visualizerCanvas = document.getElementById('audioVisualizer');
        let visualizerContext = visualizerCanvas.getContext('2d');
        let audioQueue = [];
        let isPlaying = false;
        let opusDecoder = null; // Opus decoder
        let visualizationRequest = null; // Animation frame request ID

        // Audio stream buffering related
        let audioBuffers = []; // Used to store all received audio data
        let totalAudioSize = 0; // Track accumulated audio size

        let audioBufferQueue = [];     // Store received audio packets
        let isAudioPlaying = false;    // Whether currently playing audio
        const BUFFER_THRESHOLD = 3;    // Buffer packet count threshold, accumulate at least 3 packets before starting playback
        const MIN_AUDIO_DURATION = 0.1; // Minimum audio length (seconds), audio shorter than this will be merged
        let streamingContext = null;   // Audio stream context
        const SAMPLE_RATE = 16000;     // Sample rate
        const CHANNELS = 1;            // Number of channels
        const FRAME_SIZE = 960;        // Frame size

        // DOM elements
        const connectButton = document.getElementById('connectButton');
        const serverUrlInput = document.getElementById('serverUrl');
        const connectionStatus = document.getElementById('connectionStatus');
        const messageInput = document.getElementById('messageInput');
        const sendTextButton = document.getElementById('sendTextButton');
        const recordButton = document.getElementById('recordButton');
        const stopButton = document.getElementById('stopButton');
        const conversationDiv = document.getElementById('conversation');
        const logContainer = document.getElementById('logContainer');

        function getAudioContextInstance() {
            if (!audioContext) {
                audioContext = new (window.AudioContext || window.webkitAudioContext)({
                    sampleRate: SAMPLE_RATE,
                    latencyHint: 'interactive'
                });
                log('Created audio context, sample rate: ' + SAMPLE_RATE + 'Hz', 'debug');
            }
            return audioContext;
        }

        // Initialize visualizer
        function initVisualizer() {
            visualizerCanvas.width = visualizerCanvas.clientWidth;
            visualizerCanvas.height = visualizerCanvas.clientHeight;
            visualizerContext.fillStyle = '#fafafa';
            visualizerContext.fillRect(0, 0, visualizerCanvas.width, visualizerCanvas.height);
        }

        // Draw audio visualization effect
        function drawVisualizer(dataArray) {
            visualizationRequest = requestAnimationFrame(() => drawVisualizer(dataArray));

            if (!isRecording) return;

            analyser.getByteFrequencyData(dataArray);

            visualizerContext.fillStyle = '#fafafa';
            visualizerContext.fillRect(0, 0, visualizerCanvas.width, visualizerCanvas.height);

            const barWidth = (visualizerCanvas.width / dataArray.length) * 2.5;
            let barHeight;
            let x = 0;

            for (let i = 0; i < dataArray.length; i++) {
                barHeight = dataArray[i] / 2;

                visualizerContext.fillStyle = `rgb(${barHeight + 100}, 50, 50)`;
                visualizerContext.fillRect(x, visualizerCanvas.height - barHeight, barWidth, barHeight);

                x += barWidth + 1;
            }
        }

        const queue = new BlockingQueue();

        // Start buffering process
        async function startAudioBuffering() {
            log("Starting audio buffering...", 'info');

            // Try to initialize decoder first, so it's ready when playing
            initOpusDecoder().catch(error => {
                log(`Pre-initialization of Opus decoder failed: ${error.message}`, 'warning');
                // Continue buffering, we'll try to initialize again when playing
            });
            const timeout = 300;
            while (true) {
                // Wait for three data packets when data is empty
                const packets = await queue.dequeue(
                    3,                       // At least 3 packets
                    timeout,                     // Wait at most 300 ms
                    (count) => {             // Timeout callback
                        log(`Buffer timeout, current buffered packets: ${count}, starting playback`, 'info');
                    }
                );
                if (packets.length) {
                    log(`Buffered ${packets.length} audio packets, starting playback`, 'info');
                    streamingContext.pushAudioBuffer(packets)
                }
                // Within 50ms, give whatever is available
                while (true) {
                    const data = await queue.dequeue(99, 50)
                    if (data.length) {
                        streamingContext.pushAudioBuffer(data)
                    } else {
                        break
                    }
                }
            }
        }

        // Play buffered audio
        async function playBufferedAudio() {
            // Ensure Opus decoder is initialized
            try {
                // Ensure audio context exists
                audioContext = getAudioContextInstance();

                // Ensure decoder is initialized
                if (!opusDecoder) {
                    log('Initializing Opus decoder...', 'info');
                    try {
                        opusDecoder = await initOpusDecoder();
                        if (!opusDecoder) {
                            throw new Error('Decoder initialization failed');
                        }
                        log('Opus decoder initialized successfully', 'success');
                    } catch (error) {
                        log('Opus decoder initialization failed: ' + error.message, 'error');
                        isAudioPlaying = false;
                        return;
                    }
                }

                // Create streaming playback context
                if (!streamingContext) {
                    streamingContext = createStreamingContext(opusDecoder, audioContext, SAMPLE_RATE, CHANNELS, MIN_AUDIO_DURATION);
                }

                streamingContext.decodeOpusFrames();
                streamingContext.startPlaying();

            } catch (error) {
                log(`Error playing buffered audio: ${error.message}`, 'error');
                isAudioPlaying = false;
                streamingContext = null;
            }
        }



        // Initialize Opus decoder - ensure complete initialization before returning
        async function initOpusDecoder() {
            if (opusDecoder) return opusDecoder; // Already initialized

            try {
                // Check if ModuleInstance exists
                if (typeof window.ModuleInstance === 'undefined') {
                    if (typeof Module !== 'undefined') {
                        // Use global Module as ModuleInstance
                        window.ModuleInstance = Module;
                        log('Using global Module as ModuleInstance', 'info');
                    } else {
                        throw new Error('Opus library not loaded, ModuleInstance and Module objects do not exist');
                    }
                }

                const mod = window.ModuleInstance;

                // Create decoder object
                opusDecoder = {
                    channels: CHANNELS,
                    rate: SAMPLE_RATE,
                    frameSize: FRAME_SIZE,
                    module: mod,
                    decoderPtr: null, // Initially null

                    // Initialize decoder
                    init: function () {
                        if (this.decoderPtr) return true; // Already initialized

                        // Get decoder size
                        const decoderSize = mod._opus_decoder_get_size(this.channels);
                        log(`Opus decoder size: ${decoderSize} bytes`, 'debug');

                        // Allocate memory
                        this.decoderPtr = mod._malloc(decoderSize);
                        if (!this.decoderPtr) {
                            throw new Error("Unable to allocate decoder memory");
                        }

                        // Initialize decoder
                        const err = mod._opus_decoder_init(
                            this.decoderPtr,
                            this.rate,
                            this.channels
                        );

                        if (err < 0) {
                            this.destroy(); // Clean up resources
                            throw new Error(`Opus decoder initialization failed: ${err}`);
                        }

                        log("Opus decoder initialized successfully", 'success');
                        return true;
                    },

                    // Decoding method
                    decode: function (opusData) {
                        if (!this.decoderPtr) {
                            if (!this.init()) {
                                throw new Error("Decoder not initialized and cannot initialize");
                            }
                        }

                        try {
                            const mod = this.module;

                            // Allocate memory for Opus data
                            const opusPtr = mod._malloc(opusData.length);
                            mod.HEAPU8.set(opusData, opusPtr);

                            // Allocate memory for PCM output
                            const pcmPtr = mod._malloc(this.frameSize * 2); // Int16 = 2 bytes

                            // Decode
                            const decodedSamples = mod._opus_decode(
                                this.decoderPtr,
                                opusPtr,
                                opusData.length,
                                pcmPtr,
                                this.frameSize,
                                0 // Do not use FEC
                            );

                            if (decodedSamples < 0) {
                                mod._free(opusPtr);
                                mod._free(pcmPtr);
                                throw new Error(`Opus decoding failed: ${decodedSamples}`);
                            }

                            // Copy decoded data
                            const decodedData = new Int16Array(decodedSamples);
                            for (let i = 0; i < decodedSamples; i++) {
                                decodedData[i] = mod.HEAP16[(pcmPtr >> 1) + i];
                            }

                            // Free memory
                            mod._free(opusPtr);
                            mod._free(pcmPtr);

                            return decodedData;
                        } catch (error) {
                            log(`Opus decoding error: ${error.message}`, 'error');
                            return new Int16Array(0);
                        }
                    },

                    // Destroy method
                    destroy: function () {
                        if (this.decoderPtr) {
                            this.module._free(this.decoderPtr);
                            this.decoderPtr = null;
                        }
                    }
                };

                // Initialize decoder
                if (!opusDecoder.init()) {
                    throw new Error("Opus decoder initialization failed");
                }

                return opusDecoder;

            } catch (error) {
                log(`Opus decoder initialization failed: ${error.message}`, 'error');
                opusDecoder = null; // Reset to null for next retry
                throw error;
            }
        }

        // Initialize audio recording and processing
        async function initAudio() {
            try {
                // Request microphone permission
                const stream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        sampleRate: 16000,  // Ensure 16kHz sample rate
                        channelCount: 1     // Ensure mono channel
                    }
                });
                log('Microphone access permission obtained', 'success');

                // Create audio context
                audioContext = getAudioContextInstance();
                const source = audioContext.createMediaStreamSource(stream);

                // Get actual audio track settings
                const audioTracks = stream.getAudioTracks();
                if (audioTracks.length > 0) {
                    const track = audioTracks[0];
                    const settings = track.getSettings();
                    log(`Actual microphone settings - Sample rate: ${settings.sampleRate || 'unknown'}Hz, Channels: ${settings.channelCount || 'unknown'}`, 'info');
                }

                // Create analyzer for visualization
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 2048;
                source.connect(analyser);

                // Try to initialize MediaRecorder, try different encoding options by priority
                try {
                    // Prefer Opus encoding
                    mediaRecorder = new MediaRecorder(stream, {
                        mimeType: 'audio/webm;codecs=opus',
                        audioBitsPerSecond: 16000
                    });
                    log('MediaRecorder initialized (using Opus encoding)', 'success');
                    log(`Selected encoding format: ${mediaRecorder.mimeType}`, 'info');
                } catch (e1) {
                    try {
                        // If Opus is not supported, try MP3
                        mediaRecorder = new MediaRecorder(stream, {
                            mimeType: 'audio/webm',
                            audioBitsPerSecond: 16000
                        });
                        log('MediaRecorder initialized (using WebM standard encoding, Opus not supported)', 'warning');
                        log(`Selected encoding format: ${mediaRecorder.mimeType}`, 'info');
                    } catch (e2) {
                        try {
                            // Try other alternative formats
                            mediaRecorder = new MediaRecorder(stream, {
                                mimeType: 'audio/ogg;codecs=opus',
                                audioBitsPerSecond: 16000
                            });
                            log('MediaRecorder initialized (using OGG+Opus encoding)', 'warning');
                            log(`Selected encoding format: ${mediaRecorder.mimeType}`, 'info');
                        } catch (e3) {
                            // Finally use default encoding
                            mediaRecorder = new MediaRecorder(stream);
                            log(`MediaRecorder initialized (using default encoding: ${mediaRecorder.mimeType})`, 'warning');
                        }
                    }
                }

                // Handle recorded data
                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                    }
                };

                // Handle data after recording ends
                mediaRecorder.onstop = async () => {
                    // Stop visualization
                    if (visualizationRequest) {
                        cancelAnimationFrame(visualizationRequest);
                        visualizationRequest = null;
                    }

                    log(`Recording ended, collected audio chunks: ${audioChunks.length}`, 'info');
                    if (audioChunks.length === 0) {
                        log('Warning: No audio data collected, please check if microphone is working properly', 'error');
                        return;
                    }

                    // Create complete recording blob
                    const blob = new Blob(audioChunks, { type: audioChunks[0].type });
                    log(`Created audio Blob, MIME type: ${audioChunks[0].type}, size: ${(blob.size / 1024).toFixed(2)} KB`, 'info');

                    // Save original chunks in case debugging is needed after clearing
                    const chunks = [...audioChunks];
                    audioChunks = [];

                    try {
                        // Convert blob to ArrayBuffer
                        const arrayBuffer = await blob.arrayBuffer();
                        const uint8Array = new Uint8Array(arrayBuffer);

                        log(`Converted to Uint8Array, ready to send, size: ${(arrayBuffer.byteLength / 1024).toFixed(2)} KB`, 'info');

                        // Check WebSocket status
                        if (!websocket) {
                            log('Error: WebSocket connection does not exist', 'error');
                            return;
                        }

                        if (websocket.readyState !== WebSocket.OPEN) {
                            log(`Error: WebSocket connection not open, current state: ${websocket.readyState}`, 'error');
                            return;
                        }

                        // Send binary audio data directly - this is the simplest and most effective way
                        try {
                            // Note: Start and end messages have been sent at the beginning and end of recording
                            // Here we only need to send audio data
                            await new Promise(resolve => setTimeout(resolve, 50));

                            // Process WebM container format, extract pure Opus data
                            // Server uses opuslib_next.Decoder, needs pure Opus frames
                            log('Processing audio data, extracting pure Opus frames...', 'info');
                            const opusData = extractOpusFrames(uint8Array);

                            // Record Opus data size
                            log(`Extracted Opus data, size: ${(opusData.byteLength / 1024).toFixed(2)} KB`, 'info');

                            // Send audio message step 2: binary audio data
                            websocket.send(opusData);
                            log(`Sent Opus audio data: ${(opusData.byteLength / 1024).toFixed(2)} KB`, 'success');
                        } catch (error) {
                            log(`Audio data sending failed: ${error.message}`, 'error');

                            // Try using base64 encoding as alternative
                            try {
                                log('Trying to send using base64 encoding...', 'info');
                                const base64Data = arrayBufferToBase64(arrayBuffer);
                                const audioDataMessage = {
                                    type: 'audio',
                                    action: 'data',
                                    format: 'opus',
                                    sample_rate: 16000,
                                    channels: 1,
                                    mime_type: chunks[0].type,
                                    encoding: 'base64',
                                    data: base64Data
                                };
                                websocket.send(JSON.stringify(audioDataMessage));
                                log(`Sent audio data using base64 encoding: ${(arrayBuffer.byteLength / 1024).toFixed(2)} KB`, 'warning');
                            } catch (base64Error) {
                                log(`All data sending methods failed: ${base64Error.message}`, 'error');
                            }
                        }
                    } catch (error) {
                        log(`Error processing recording data: ${error.message}`, 'error');
                    }
                };

                // Try to initialize Opus decoder
                try {
                    // Check if ModuleInstance exists (global variable exported by local library)
                    if (typeof window.ModuleInstance === 'undefined') {
                        throw new Error('Opus library not loaded, ModuleInstance object does not exist');
                    }

                    // Simple test to see if ModuleInstance is available
                    if (typeof window.ModuleInstance._opus_decoder_get_size === 'function') {
                        const testSize = window.ModuleInstance._opus_decoder_get_size(1);
                        log(`Opus decoder test successful, decoder size: ${testSize} bytes`, 'success');
                    } else {
                        throw new Error('Opus decoding function not found');
                    }
                } catch (err) {
                    log(`Opus decoder initialization warning: ${err.message}, will retry when needed`, 'warning');
                }

                log('Audio system initialization completed', 'success');
                return true;
            } catch (error) {
                log(`Audio initialization error: ${error.message}`, 'error');
                return false;
            }
        }

        // Start recording
        function startRecording() {
            if (isRecording) return;

            try {
                // Minimum recording duration reminder
                log('Please record at least 1-2 seconds of audio to ensure sufficient data collection', 'info');

                // Get server type - determine from URL
                const serverUrl = serverUrlInput.value.trim();
                let isXiaozhiNative = false;

                // Check if it's Xiaozhi native server (determine by URL characteristics)
                if (serverUrl.includes('xiaozhi') || serverUrl.includes('localhost') || serverUrl.includes('127.0.0.1')) {
                    isXiaozhiNative = true;
                    log('Detected Xiaozhi native server, using standard listen protocol', 'info');
                }

                // Use direct PCM recording and libopus encoding approach
                startDirectRecording();
            } catch (error) {
                log(`Recording startup error: ${error.message}`, 'error');
            }
        }

        // Stop recording
        function stopRecording() {
            if (!isRecording) return;

            try {
                // Use direct PCM recording stop
                stopDirectRecording();
            } catch (error) {
                log(`Stop recording error: ${error.message}`, 'error');
            }
        }

        // Connect to WebSocket server
        async function connectToServer() {
            const url = serverUrlInput.value.trim();
            const config = getConfig();
            // First check OTA status
            log('Checking OTA status...', 'info');
            const otaUrl = document.getElementById('otaUrl').value.trim();
            localStorage.setItem('otaUrl', otaUrl);
            localStorage.setItem('wsUrl', url);

            try {
                const ws = await webSocketConnect(otaUrl, url, config)
                if (ws === undefined) {
                    return
                }
                websocket = ws

                // Set binary data reception type to ArrayBuffer
                websocket.binaryType = 'arraybuffer';

                websocket.onopen = async () => {
                    log(`Connected to server: ${url}`, 'success');
                    connectionStatus.textContent = 'ws connected';
                    connectionStatus.style.color = 'green';

                    // Send hello message after successful connection
                    await sendHelloMessage();

                    connectButton.textContent = 'Disconnect';
                    connectButton.removeEventListener('click', connectToServer);
                    connectButton.addEventListener('click', disconnectFromServer);
                    // connectButton.onclick = disconnectFromServer;
                    messageInput.disabled = false;
                    sendTextButton.disabled = false;

                    const audioInitialized = await initAudio();
                    if (audioInitialized) {
                        recordButton.disabled = false;
                    }
                };

                websocket.onclose = () => {
                    log('Disconnected', 'info');
                    connectionStatus.textContent = 'ws disconnected';
                    connectionStatus.style.color = 'red';

                    connectButton.textContent = 'Connect';
                    connectButton.removeEventListener('click', disconnectFromServer);
                    connectButton.addEventListener('click', connectToServer);
                    // connectButton.onclick = connectToServer;
                    messageInput.disabled = true;
                    sendTextButton.disabled = true;
                    recordButton.disabled = true;
                    stopButton.disabled = true;
                };

                websocket.onerror = (error) => {
                    log(`WebSocket error: ${error.message || 'Unknown error'}`, 'error');
                    connectionStatus.textContent = 'ws not connected';
                    connectionStatus.style.color = 'red';
                };

                websocket.onmessage = function (event) {
                    try {
                        // Check if it's a text message
                        if (typeof event.data === 'string') {
                            const message = JSON.parse(event.data);

                            if (message.type === 'hello') {
                                log(`Server response: ${JSON.stringify(message, null, 2)}`, 'success');
                            } else if (message.type === 'tts') {
                                // TTS status message
                                if (message.state === 'start') {
                                    log('Server started sending speech', 'info');
                                } else if (message.state === 'sentence_start') {
                                    log(`Server sending speech segment: ${message.text}`, 'info');
                                    // Add text to conversation record
                                    if (message.text) {
                                        addMessage(message.text);
                                    }
                                } else if (message.state === 'sentence_end') {
                                    log(`Speech segment ended: ${message.text}`, 'info');
                                } else if (message.state === 'stop') {
                                    log('Server speech transmission ended', 'info');
                                    // Update UI state after ending
                                    if (recordButton.disabled) {
                                        recordButton.disabled = false;
                                        recordButton.textContent = 'Start Recording';
                                        recordButton.classList.remove('recording');
                                    }
                                }
                            } else if (message.type === 'audio') {
                                // Audio control message
                                log(`Received audio control message: ${JSON.stringify(message)}`, 'info');
                            } else if (message.type === 'stt') {
                                // Speech recognition result
                                log(`Recognition result: ${message.text}`, 'info');
                                // Add recognition result to conversation record
                                addMessage(`[Speech Recognition] ${message.text}`, true);
                            } else if (message.type === 'llm') {
                                // Large model response
                                log(`Large model response: ${message.text}`, 'info');
                                // Add large model response to conversation record
                                if (message.text && message.text !== '😊') {
                                    addMessage(message.text);
                                }
                            } else if (message.type === 'mcp') {
                                const payload = message.payload || {};
                                log(`Server sent: ${JSON.stringify(message)}`, 'info');
                                if (payload) {
                                    // Simulate Xiaozhi client behavior
                                    if (payload.method === 'tools/list') {
                                        const replay_message = JSON.stringify({
                                            "session_id": "", "type": "mcp", "payload": {
                                                "jsonrpc": "2.0", "id": 2, "result": {
                                                    "tools": [{
                                                        "name": "self.get_device_status",
                                                        "description": "Provides the real-time information of the device, including the current status of the audio speaker, screen, battery, network, etc.\nUse this tool for: \n1. Answering questions about current condition (e.g. what is the current volume of the audio speaker?)\n2. As the first step to control the device (e.g. turn up / down the volume of the audio speaker, etc.)",
                                                        "inputSchema": { "type": "object", "properties": {} }
                                                    }, {
                                                        "name": "self.audio_speaker.set_volume",
                                                        "description": "Set the volume of the audio speaker. If the current volume is unknown, you must call `self.get_device_status` tool first and then call this tool.",
                                                        "inputSchema": {
                                                            "type": "object",
                                                            "properties": {
                                                                "volume": {
                                                                    "type": "integer",
                                                                    "minimum": 0,
                                                                    "maximum": 100
                                                                }
                                                            },
                                                            "required": ["volume"]
                                                        }
                                                    }, {
                                                        "name": "self.screen.set_brightness",
                                                        "description": "Set the brightness of the screen.",
                                                        "inputSchema": {
                                                            "type": "object",
                                                            "properties": {
                                                                "brightness": {
                                                                    "type": "integer",
                                                                    "minimum": 0,
                                                                    "maximum": 100
                                                                }
                                                            },
                                                            "required": ["brightness"]
                                                        }
                                                    }, {
                                                        "name": "self.screen.set_theme",
                                                        "description": "Set the theme of the screen. The theme can be 'light' or 'dark'.",
                                                        "inputSchema": {
                                                            "type": "object",
                                                            "properties": { "theme": { "type": "string" } },
                                                            "required": ["theme"]
                                                        }
                                                    }]
                                                }
                                            }
                                        })
                                        websocket.send(replay_message);
                                        log(`Reply MCP message: ${replay_message}`, 'info');
                                    } else if (payload.method === 'tools/call') {
                                        // Simulate reply
                                        const replay_message = JSON.stringify({
                                            "session_id": "9f261599",
                                            "type": "mcp",
                                            "payload": {
                                                "jsonrpc": "2.0",
                                                "id": payload.id,
                                                "result": { "content": [{ "type": "text", "text": "true" }], "isError": false }
                                            }
                                        })
                                        websocket.send(replay_message);
                                        log(`Reply MCP message: ${replay_message}`, 'info');
                                    }
                                }

                            } else {
                                // Unknown message type
                                log(`Unknown message type: ${message.type}`, 'info');
                                addMessage(JSON.stringify(message, null, 2));
                            }
                        } else {
                            // Handle binary data - compatible with multiple binary formats
                            handleBinaryMessage(event.data);
                        }
                    } catch (error) {
                        log(`WebSocket message processing error: ${error.message}`, 'error');
                        // Non-JSON format text messages display directly
                        if (typeof event.data === 'string') {
                            addMessage(event.data);
                        }
                    }
                };

                connectionStatus.textContent = 'ws not connected';
                connectionStatus.style.color = 'orange';
            } catch (error) {
                log(`Connection error: ${error.message}`, 'error');
                connectionStatus.textContent = 'ws not connected';
            }
        }

        // Send hello handshake message
        async function sendHelloMessage() {
            if (!websocket || websocket.readyState !== WebSocket.OPEN) return;

            try {
                const config = getConfig();

                // Set device information
                const helloMessage = {
                    type: 'hello',
                    device_id: config.deviceId,
                    device_name: config.deviceName,
                    device_mac: config.deviceMac,
                    token: config.token,
                    features: {
                        mcp: true
                    }
                };

                log('Sending hello handshake message', 'info');
                websocket.send(JSON.stringify(helloMessage));

                // Wait for server response
                return new Promise(resolve => {
                    // 5 second timeout
                    const timeout = setTimeout(() => {
                        log('Hello response timeout', 'error');
                        log('Tip: Please try clicking the "Test Auth" button for connection troubleshooting', 'info');
                        resolve(false);
                    }, 5000);

                    // Temporarily listen for one message to receive hello response
                    const onMessageHandler = (event) => {
                        try {
                            const response = JSON.parse(event.data);
                            if (response.type === 'hello' && response.session_id) {
                                log(`Server handshake successful, session ID: ${response.session_id}`, 'success');
                                clearTimeout(timeout);
                                websocket.removeEventListener('message', onMessageHandler);
                                resolve(true);
                            }
                        } catch (e) {
                            // Ignore non-JSON messages
                        }
                    };

                    websocket.addEventListener('message', onMessageHandler);
                });
            } catch (error) {
                log(`Send hello message error: ${error.message}`, 'error');
                return false;
            }
        }

        // Disconnect WebSocket connection
        function disconnectFromServer() {
            if (!websocket) return;

            websocket.close();
            stopRecording();
        }

        // Send text message
        function sendTextMessage() {
            const message = messageInput.value.trim();
            if (message === '' || !websocket || websocket.readyState !== WebSocket.OPEN) return;


            try {
                // Send listen message directly, no need to repeat hello
                const listenMessage = {
                    type: 'listen',
                    mode: 'manual',
                    state: 'detect',
                    text: message
                };

                websocket.send(JSON.stringify(listenMessage));
                addMessage(message, true);
                log(`Sending text message: ${message}`, 'info');

                messageInput.value = '';
            } catch (error) {
                log(`Send message error: ${error.message}`, 'error');
            }
        }

        // Generate random MAC address
        function generateRandomMac() {
            const hexDigits = '0123456789ABCDEF';
            let mac = '';
            for (let i = 0; i < 6; i++) {
                if (i > 0) mac += ':';
                for (let j = 0; j < 2; j++) {
                    mac += hexDigits.charAt(Math.floor(Math.random() * 16));
                }
            }
            return mac;
        }

        // Initialize event listeners
        function initEventListeners() {
            connectButton.addEventListener('click', connectToServer);
            document.getElementById('authTestButton').addEventListener('click', testAuthentication);

            // Device configuration panel collapse/expand
            const toggleButton = document.getElementById('toggleConfig');
            const configPanel = document.getElementById('configPanel');
            const deviceMacInput = document.getElementById('deviceMac');
            const clientIdInput = document.getElementById('clientId');
            const displayMac = document.getElementById('displayMac');
            const displayClient = document.getElementById('displayClient');

            // Load MAC address from localStorage, generate new one if not available
            let savedMac = localStorage.getItem('deviceMac');
            if (!savedMac) {
                savedMac = generateRandomMac();
                localStorage.setItem('deviceMac', savedMac);
            }
            deviceMacInput.value = savedMac;
            displayMac.textContent = savedMac;

            // Update displayed values
            function updateDisplayValues() {
                const newMac = deviceMacInput.value;
                displayMac.textContent = newMac;
                displayClient.textContent = clientIdInput.value;
                // Save MAC address to localStorage
                localStorage.setItem('deviceMac', newMac);
            }

            // Listen for input changes
            deviceMacInput.addEventListener('input', updateDisplayValues);
            clientIdInput.addEventListener('input', updateDisplayValues);

            // Initial update of displayed values
            updateDisplayValues();

            const savedOtaUrl = localStorage.getItem('otaUrl');
            if (savedOtaUrl) {
                document.getElementById('otaUrl').value = savedOtaUrl;
            }

            const savedWsUrl = localStorage.getItem('wsUrl');
            if (savedWsUrl) {
                document.getElementById('serverUrl').value = savedWsUrl;
            }

            // Toggle panel display
            toggleButton.addEventListener('click', () => {
                const isExpanded = configPanel.classList.contains('expanded');
                configPanel.classList.toggle('expanded');
                toggleButton.textContent = isExpanded ? 'Edit' : 'Collapse';
            });

            // Tab switching
            const tabs = document.querySelectorAll('.tab');
            tabs.forEach(tab => {
                tab.addEventListener('click', () => {
                    // Remove active class from all tabs
                    tabs.forEach(t => t.classList.remove('active'));
                    document.querySelectorAll('.tab-content').forEach(c => c.classList.remove('active'));

                    // Add active class to current tab
                    tab.classList.add('active');
                    document.getElementById(`${tab.dataset.tab}Tab`).classList.add('active');
                });
            });

            sendTextButton.addEventListener('click', sendTextMessage);
            messageInput.addEventListener('keypress', (e) => {
                if (e.key === 'Enter') sendTextMessage();
            });

            recordButton.addEventListener('click', () => {
                if (isRecording) {
                    stopRecording();
                } else {
                    startRecording();
                }
            });

            window.addEventListener('resize', initVisualizer);
        }

        // Test authentication
        async function testAuthentication() {
            log('Starting authentication test...', 'info');

            const config = getConfig();

            // Display server configuration
            log('-------- Server Authentication Configuration Check --------', 'info');
            log('Please confirm auth configuration in config.yaml:', 'info');
            log('1. server.auth.enabled is false or server has correct authentication configured', 'info');
            log('2. If authentication is enabled, please confirm using correct token', 'info');
            log(`3. Or added test device MAC to allowed_devices: ${config.deviceMac}`, 'info');

            const serverUrl = serverUrlInput.value.trim();
            if (!serverUrl) {
                log('Please enter server address', 'error');
                return;
            }

            // Test connection
            log('Trying connections with different authentication parameters:', 'info');

            // Test 1: Connection without parameters
            try {
                log('Test 1: Trying connection without parameters...', 'info');
                const ws1 = new WebSocket(serverUrl);

                ws1.onopen = () => {
                    log('Test 1 successful: Connection without parameters works, server may not have authentication enabled', 'success');
                    ws1.close();
                };

                ws1.onerror = (error) => {
                    log('Test 1 failed: Connection without parameters rejected, server may have authentication enabled', 'error');
                };

                // Close test connection after 5 seconds
                setTimeout(() => {
                    if (ws1.readyState === WebSocket.CONNECTING || ws1.readyState === WebSocket.OPEN) {
                        ws1.close();
                    }
                }, 5000);
            } catch (error) {
                log(`Test 1 error: ${error.message}`, 'error');
            }

            // Test 2: Connection with parameters
            setTimeout(async () => {
                try {
                    log('Test 2: Trying connection with token parameters...', 'info');

                    let url = new URL(serverUrl);
                    url.searchParams.append('token', config.token);
                    url.searchParams.append('device_id', config.deviceId);
                    url.searchParams.append('device_mac', config.deviceMac);

                    const ws2 = new WebSocket(url.toString());

                    ws2.onopen = () => {
                        log('Test 2 successful: Connection with token parameters works', 'success');

                        // Try to send hello message
                        const helloMsg = {
                            type: 'hello',
                            device_id: config.deviceId,
                            device_mac: config.deviceMac,
                            token: config.token
                        };

                        ws2.send(JSON.stringify(helloMsg));
                        log('Sent hello test message', 'info');

                        // Listen for response
                        ws2.onmessage = (event) => {
                            try {
                                const response = JSON.parse(event.data);
                                if (response.type === 'hello' && response.session_id) {
                                    log(`Test completely successful! Received hello response, session ID: ${response.session_id}`, 'success');
                                    ws2.close();
                                }
                            } catch (e) {
                                log(`Received non-JSON response: ${event.data}`, 'info');
                            }
                        };

                        // Close after 5 seconds
                        setTimeout(() => ws2.close(), 5000);
                    };

                    ws2.onerror = (error) => {
                        log('Test 2 failed: Connection with token parameters rejected', 'error');
                        log('Please check if token is correct, or if server accepts URL parameter authentication', 'error');
                    };
                } catch (error) {
                    log(`Test 2 error: ${error.message}`, 'error');
                }
            }, 6000);

            log('Authentication test started, please check test results...', 'info');
        }

        // Helper function: ArrayBuffer to Base64
        function arrayBufferToBase64(buffer) {
            let binary = '';
            const bytes = new Uint8Array(buffer);
            const len = bytes.byteLength;
            for (let i = 0; i < len; i++) {
                binary += String.fromCharCode(bytes[i]);
            }
            return window.btoa(binary);
        }

        // Opus encoder
        let opusEncoder;

        // Initialize application
        function initApp() {
            initVisualizer();
            initEventListeners();

            // Check if libopus.js is loaded correctly
            checkOpusLoaded();

            // Initialize Opus encoder
            opusEncoder = initOpusEncoder();

            // Preload Opus decoder
            log('Preloading Opus decoder...', 'info');
            initOpusDecoder().then(() => {
                log('Opus decoder preloaded successfully', 'success');
            }).catch(error => {
                log(`Opus decoder preload failed: ${error.message}, will retry when needed`, 'warning');
            });
            playBufferedAudio()
            startAudioBuffering()

        }

        // PCM recording processor code - will be injected into AudioWorklet
        const audioProcessorCode = `
            class AudioRecorderProcessor extends AudioWorkletProcessor {
                constructor() {
                    super();
                    this.buffers = [];
                    this.frameSize = 960; // 60ms @ 16kHz = 960 samples
                    this.buffer = new Int16Array(this.frameSize);
                    this.bufferIndex = 0;
                    this.isRecording = false;

                    // Listen for messages from main thread
                    this.port.onmessage = (event) => {
                        if (event.data.command === 'start') {
                            this.isRecording = true;
                            this.port.postMessage({ type: 'status', status: 'started' });
                        } else if (event.data.command === 'stop') {
                            this.isRecording = false;

                            // Send remaining buffer
                            if (this.bufferIndex > 0) {
                                const finalBuffer = this.buffer.slice(0, this.bufferIndex);
                                this.port.postMessage({
                                    type: 'buffer',
                                    buffer: finalBuffer
                                });
                                this.bufferIndex = 0;
                            }

                            this.port.postMessage({ type: 'status', status: 'stopped' });
                        }
                    };
                }

                process(inputs, outputs, parameters) {
                    if (!this.isRecording) return true;

                    const input = inputs[0][0]; // Get first input channel
                    if (!input) return true;

                    // Convert float samples to 16-bit integers and store
                    for (let i = 0; i < input.length; i++) {
                        if (this.bufferIndex >= this.frameSize) {
                            // Buffer is full, send to main thread and reset
                            this.port.postMessage({
                                type: 'buffer',
                                buffer: this.buffer.slice(0)
                            });
                            this.bufferIndex = 0;
                        }

                        // Convert to 16-bit integer (-32768 to 32767)
                        this.buffer[this.bufferIndex++] = Math.max(-32768, Math.min(32767, Math.floor(input[i] * 32767)));
                    }

                    return true;
                }
            }

            registerProcessor('audio-recorder-processor', AudioRecorderProcessor);
        `;

        // Create audio processor
        async function createAudioProcessor() {
            audioContext = getAudioContextInstance();

            try {
                // Check if AudioWorklet is supported
                if (audioContext.audioWorklet) {
                    // Register audio processor
                    const blob = new Blob([audioProcessorCode], { type: 'application/javascript' });
                    const url = URL.createObjectURL(blob);
                    await audioContext.audioWorklet.addModule(url);
                    URL.revokeObjectURL(url);

                    // Create audio processing node
                    const audioProcessor = new AudioWorkletNode(audioContext, 'audio-recorder-processor');

                    // Set up audio processing message handling
                    audioProcessor.port.onmessage = (event) => {
                        if (event.data.type === 'buffer') {
                            // Received PCM buffer data
                            processPCMBuffer(event.data.buffer);
                        }
                    };

                    log('Using AudioWorklet for audio processing', 'success');
                    return { node: audioProcessor, type: 'worklet' };
                } else {
                    // Use legacy ScriptProcessorNode as fallback
                    log('AudioWorklet not available, using ScriptProcessorNode as fallback', 'warning');

                    const frameSize = 4096; // ScriptProcessorNode buffer size
                    const scriptProcessor = audioContext.createScriptProcessor(frameSize, 1, 1);

                    // Set audioProcess event to handle audio data
                    scriptProcessor.onaudioprocess = (event) => {
                        if (!isRecording) return;

                        const input = event.inputBuffer.getChannelData(0);
                        const buffer = new Int16Array(input.length);

                        // Convert float data to 16-bit integers
                        for (let i = 0; i < input.length; i++) {
                            buffer[i] = Math.max(-32768, Math.min(32767, Math.floor(input[i] * 32767)));
                        }

                        // Process PCM data
                        processPCMBuffer(buffer);
                    };

                    // Need to connect output, otherwise processing won't be triggered
                    // We create a silent channel
                    const silent = audioContext.createGain();
                    silent.gain.value = 0;
                    scriptProcessor.connect(silent);
                    silent.connect(audioContext.destination);

                    return { node: scriptProcessor, type: 'processor' };
                }
            } catch (error) {
                log(`Failed to create audio processor: ${error.message}, trying fallback`, 'error');

                // Final fallback: use ScriptProcessorNode
                try {
                    const frameSize = 4096; // ScriptProcessorNode buffer size
                    const scriptProcessor = audioContext.createScriptProcessor(frameSize, 1, 1);

                    scriptProcessor.onaudioprocess = (event) => {
                        if (!isRecording) return;

                        const input = event.inputBuffer.getChannelData(0);
                        const buffer = new Int16Array(input.length);

                        for (let i = 0; i < input.length; i++) {
                            buffer[i] = Math.max(-32768, Math.min(32767, Math.floor(input[i] * 32767)));
                        }

                        processPCMBuffer(buffer);
                    };

                    const silent = audioContext.createGain();
                    silent.gain.value = 0;
                    scriptProcessor.connect(silent);
                    silent.connect(audioContext.destination);

                    log('Successfully using ScriptProcessorNode as fallback', 'warning');
                    return { node: scriptProcessor, type: 'processor' };
                } catch (fallbackError) {
                    log(`Fallback also failed: ${fallbackError.message}`, 'error');
                    return null;
                }
            }
        }

        // Initialize system for direct PCM data recording
        let audioProcessor = null;
        let audioProcessorType = null;
        let audioSource = null;

        // Process PCM buffer data
        let pcmDataBuffer = new Int16Array();

        function processPCMBuffer(buffer) {
            if (!isRecording) return;

            // Append new PCM data to buffer
            const newBuffer = new Int16Array(pcmDataBuffer.length + buffer.length);
            newBuffer.set(pcmDataBuffer);
            newBuffer.set(buffer, pcmDataBuffer.length);
            pcmDataBuffer = newBuffer;

            // Check if there's enough data for Opus encoding (16000Hz, 60ms = 960 samples)
            const samplesPerFrame = 960; // 60ms @ 16kHz

            while (pcmDataBuffer.length >= samplesPerFrame) {
                // Extract one frame of data from buffer
                const frameData = pcmDataBuffer.slice(0, samplesPerFrame);
                pcmDataBuffer = pcmDataBuffer.slice(samplesPerFrame);

                // Encode to Opus
                encodeAndSendOpus(frameData);
            }
        }

        // Encode and send Opus data
        function encodeAndSendOpus(pcmData = null) {
            if (!opusEncoder) {
                log('Opus encoder not initialized', 'error');
                return;
            }

            try {
                // If PCM data is provided, encode that data
                if (pcmData) {
                    // Use initialized Opus encoder to encode
                    const opusData = opusEncoder.encode(pcmData);

                    if (opusData && opusData.length > 0) {
                        // Store audio frame
                        audioBuffers.push(opusData.buffer);
                        totalAudioSize += opusData.length;

                        // If WebSocket is connected, send data
                        if (websocket && websocket.readyState === WebSocket.OPEN) {
                            try {
                                // Server expects raw Opus data, no additional wrapping needed
                                websocket.send(opusData.buffer);
                                log(`Sent Opus frame, size: ${opusData.length} bytes`, 'debug');
                            } catch (error) {
                                log(`WebSocket send error: ${error.message}`, 'error');
                            }
                        }
                    } else {
                        log('Opus encoding failed, no valid data returned', 'error');
                    }
                } else {
                    // Process remaining PCM data
                    if (pcmDataBuffer.length > 0) {
                        // If remaining samples are insufficient for one frame, pad with silence
                        const samplesPerFrame = 960;
                        if (pcmDataBuffer.length < samplesPerFrame) {
                            const paddedBuffer = new Int16Array(samplesPerFrame);
                            paddedBuffer.set(pcmDataBuffer);
                            // Remaining part is 0 (silence)
                            encodeAndSendOpus(paddedBuffer);
                        } else {
                            encodeAndSendOpus(pcmDataBuffer.slice(0, samplesPerFrame));
                        }
                        pcmDataBuffer = new Int16Array(0);
                    }
                }
            } catch (error) {
                log(`Opus encoding error: ${error.message}`, 'error');
            }
        }

        // Start direct recording from PCM data
        async function startDirectRecording() {
            if (isRecording) return;

            try {
                // Initialize Opus encoder
                if (!initOpusEncoder()) {
                    log('Cannot start recording: Opus encoder initialization failed', 'error');
                    return;
                }

                // Request microphone permission
                const stream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        sampleRate: 16000,
                        channelCount: 1
                    }
                });

                // Create audio context and analyzer
                audioContext = getAudioContextInstance();

                // Create audio processor
                const processorResult = await createAudioProcessor();
                if (!processorResult) {
                    log('Cannot create audio processor', 'error');
                    return;
                }

                audioProcessor = processorResult.node;
                audioProcessorType = processorResult.type;

                // Connect audio processing chain
                audioSource = audioContext.createMediaStreamSource(stream);
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 2048;

                audioSource.connect(analyser);
                audioSource.connect(audioProcessor);

                // Start recording
                pcmDataBuffer = new Int16Array();
                audioBuffers = [];
                totalAudioSize = 0;
                isRecording = true;

                // Start audio processor recording - only AudioWorklet needs to send messages
                if (audioProcessorType === 'worklet' && audioProcessor.port) {
                    audioProcessor.port.postMessage({ command: 'start' });
                }

                // Send listen start message
                if (websocket && websocket.readyState === WebSocket.OPEN) {
                    // Use listen message format expected by server
                    const listenMessage = {
                        type: 'listen',
                        mode: 'manual',  // Use manual mode, we control start/stop
                        state: 'start'   // Indicates start recording
                    };

                    log(`Sending recording start message: ${JSON.stringify(listenMessage)}`, 'info');
                    websocket.send(JSON.stringify(listenMessage));
                } else {
                    log('WebSocket not connected, cannot send start message', 'error');
                    return false;
                }

                // Start audio visualization
                const dataArray = new Uint8Array(analyser.frequencyBinCount);
                drawVisualizer(dataArray);

                // Display recording timer on UI
                let recordingSeconds = 0;
                const recordingTimer = setInterval(() => {
                    recordingSeconds += 0.1;
                    recordButton.textContent = `Stop Recording ${recordingSeconds.toFixed(1)}s`;
                }, 100);

                // Save timer for clearing when stopping
                window.recordingTimer = recordingTimer;

                recordButton.classList.add('recording');
                recordButton.disabled = false;

                log('Started PCM direct recording', 'success');
                return true;
            } catch (error) {
                log(`Direct recording startup error: ${error.message}`, 'error');
                isRecording = false;
                return false;
            }
        }

        // Stop direct recording from PCM data
        function stopDirectRecording() {
            if (!isRecording) return;

            try {
                // Stop recording
                isRecording = false;

                // Stop audio processor recording
                if (audioProcessor) {
                    // Only AudioWorklet needs to send stop message
                    if (audioProcessorType === 'worklet' && audioProcessor.port) {
                        audioProcessor.port.postMessage({ command: 'stop' });
                    }

                    audioProcessor.disconnect();
                    audioProcessor = null;
                }

                // Disconnect audio connections
                if (audioSource) {
                    audioSource.disconnect();
                    audioSource = null;
                }

                // Stop visualization
                if (visualizationRequest) {
                    cancelAnimationFrame(visualizationRequest);
                    visualizationRequest = null;
                }

                // Clear recording timer
                if (window.recordingTimer) {
                    clearInterval(window.recordingTimer);
                    window.recordingTimer = null;
                }

                // Encode and send remaining data
                encodeAndSendOpus();

                // Send an empty message as an end marker (simulate receiving empty audio data)
                if (websocket && websocket.readyState === WebSocket.OPEN) {
                    // Use empty Uint8Array to send the last empty frame
                    const emptyOpusFrame = new Uint8Array(0);
                    websocket.send(emptyOpusFrame);

                    // Send listen end message
                    const stopMessage = {
                        type: 'listen',
                        mode: 'manual',
                        state: 'stop'
                    };

                    websocket.send(JSON.stringify(stopMessage));
                    log('Recording stop signal sent', 'info');
                }

                // Reset UI
                recordButton.textContent = 'Start Recording';
                recordButton.classList.remove('recording');
                recordButton.disabled = false;

                log('Stopped PCM direct recording', 'success');
                return true;
            } catch (error) {
                log(`Direct recording stop error: ${error.message}`, 'error');
                return false;
            }
        }

        async function handleBinaryMessage(data) {
            try {
                let arrayBuffer;
                // Process based on data type
                if (data instanceof ArrayBuffer) {
                    arrayBuffer = data;
                    log(`Received ArrayBuffer audio data, size: ${data.byteLength} bytes`, 'debug');
                } else if (data instanceof Blob) {
                    // If it's Blob type, convert to ArrayBuffer
                    arrayBuffer = await data.arrayBuffer();
                    log(`Received Blob audio data, size: ${arrayBuffer.byteLength} bytes`, 'debug');
                } else {
                    log(`Received unknown type of binary data: ${typeof data}`, 'warning');
                    return;
                }
                // Create Uint8Array for processing
                const opusData = new Uint8Array(arrayBuffer);
                if (opusData.length > 0) {
                    // Add data to buffer queue
                    queue.enqueue(opusData);
                } else {
                    log('Received empty audio data frame, possibly end marker', 'warning');
                    // If currently playing, send end signal
                    if (isAudioPlaying && streamingContext) {
                        streamingContext.endOfStream = true;
                    }
                }
            } catch (error) {
                log(`Error processing binary message: ${error.message}`, 'error');
            }
        }

        // Get configuration values
        function getConfig() {
            const deviceMac = document.getElementById('deviceMac').value.trim();
            return {
                deviceId: deviceMac,  // Use MAC address as deviceId
                deviceName: document.getElementById('deviceName').value.trim(),
                deviceMac: deviceMac,
                clientId: document.getElementById('clientId').value.trim(),
                token: document.getElementById('token').value.trim()
            };
        }

        initApp();
    </script>
</body>

</html>